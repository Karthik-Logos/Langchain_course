{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set the API key in the environment variable\n",
    "os.environ['OPENAI_API_KEY'] = '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'\n",
    "os.environ['TAVILY_API_KEY'] = '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'\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyCHNjlgN2WACMAAjhll2RM01dNyBRAPe1I\"\n",
    "os.environ[\"GOOGLE_CSE_ID\"] = \"53930e90b3145465e\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Agents in LangChain\n",
    "\n",
    "In this notebook, we will explore the concept of agents in LangChain, their types, and how to build and use them effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are Agents?\n",
    "\n",
    "Agents in LangChain are autonomous systems that use language models to determine which actions to take and in what order to achieve a specific goal. They provide a more dynamic approach to working with language models by allowing them to make decisions about tool usage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why Use Agents?\n",
    "\n",
    "- Dynamic tool selection: Agents can choose which tools to use based on the task, rather than following a predefined sequence.\n",
    "- Complex reasoning: Agents can handle multi-step tasks that require reasoning about which tools to use when.\n",
    "- Adaptability: They can adjust their approach based on intermediate results.\n",
    "- Autonomy: Agents can work more independently to solve problems with less human guidance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Unlike Chains (which follow a fixed sequence), Agents can make decisions in real-time.\n",
    "- Agents use LLMs + tools to complete tasks dynamically.\n",
    "- They operate based on a prompting strategy like ReAct (Reason + Act).\n",
    "\n",
    "##### Example Use Cases:\n",
    "- A chatbot that searches the web before answering.\n",
    "- An AI assistant that solves math problems when needed.\n",
    "- A customer support bot that retrieves data from APIs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **How to Create LangChain Agents**\n",
    "\n",
    "To build an effective agent in LangChain, you need these key components:\n",
    "\n",
    "- **Tools:** Functions that agents can use to interact with the world (APIs, databases, calculators, etc.)\n",
    "- **Language Model:** The core reasoning engine (like GPT-4, Claude, or Llama)\n",
    "- **Agent Type/Framework:** The decision-making approach (ReAct, OpenAI Functions, etc.)\n",
    "- **Prompt Template:** Instructions that guide the agent's behavior\n",
    "- **Memory:** Optional component for maintaining context across interactions\n",
    "- **Agent Executor:** Runs the agent, handling the flow between the agent and tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types of Agents\n",
    "\n",
    "LangChain supports several types of agents, each designed for specific use cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. ReAct Agent**\n",
    "- The ReAct agent (Reasoning and Acting) explicitly traces its reasoning process through a \"Thought, Action, Observation\" cycle. This makes it excellent for tasks requiring step-by-step reasoning.\n",
    "\n",
    "\n",
    "#### **Key characteristics:**\n",
    "\n",
    "- Explicitly shows its reasoning process\n",
    "- Good for debugging agent behavior\n",
    "- Works well with a variety of LLMs\n",
    "- Uses a predefined format to structure the agent's thinking\n",
    "\n",
    "- This agent type is ideal for tasks requiring transparent reasoning like: Math problem solving ,\n",
    "Multi-step research ,\n",
    "Logical deductions ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: We need to find the population of France and then multiply it by 2.\n",
      "Action: search\n",
      "Action Input: Population of France\u001b[0m\u001b[36;1m\u001b[1;3mSearch results for: Population of France\n",
      "- France has a population of 67.75 million people (2023 estimate)\n",
      "- Paris is the capital of France\u001b[0m\u001b[32;1m\u001b[1;3mWe have found the population of France, now we need to multiply it by 2.\n",
      "Action: calculator\n",
      "Action Input: 67.75 million * 2\u001b[0m\u001b[33;1m\u001b[1;3mError in calculation: invalid syntax (<string>, line 1)\u001b[0m\u001b[32;1m\u001b[1;3mI need to convert the population of France from million to a numerical value before multiplying by 2.\n",
      "Action: calculator\n",
      "Action Input: 67.75 * 1000000 * 2\u001b[0m\u001b[33;1m\u001b[1;3m135500000.0\u001b[0m\u001b[32;1m\u001b[1;3mI now know the final answer\n",
      "Final Answer: The population of France multiplied by 2 is 135,500,000.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Final Response:\n",
      "The population of France multiplied by 2 is 135,500,000.\n",
      "\n",
      "Intermediate Steps:\n",
      "(AgentAction(tool='search', tool_input='Population of France', log='Thought: We need to find the population of France and then multiply it by 2.\\nAction: search\\nAction Input: Population of France'), 'Search results for: Population of France\\n- France has a population of 67.75 million people (2023 estimate)\\n- Paris is the capital of France')\n",
      "(AgentAction(tool='calculator', tool_input='67.75 million * 2', log='We have found the population of France, now we need to multiply it by 2.\\nAction: calculator\\nAction Input: 67.75 million * 2'), 'Error in calculation: invalid syntax (<string>, line 1)')\n",
      "(AgentAction(tool='calculator', tool_input='67.75 * 1000000 * 2', log='I need to convert the population of France from million to a numerical value before multiplying by 2.\\nAction: calculator\\nAction Input: 67.75 * 1000000 * 2'), '135500000.0')\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "ReAct Agent Example\n",
    "\n",
    "This example demonstrates how to create a ReAct agent in LangChain.\n",
    "ReAct stands for \"Reasoning and Acting\" - it explicitly traces the agent's reasoning.\n",
    "\"\"\"\n",
    "\n",
    "from langchain_core.tools import tool\n",
    "from langchain.agents import AgentExecutor, create_react_agent\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# Step 1: Define tools the agent can use\n",
    "@tool\n",
    "def search(query: str) -> str:\n",
    "    \"\"\"Search for information about a topic.\"\"\"\n",
    "    # In a real implementation, this would connect to a search API\n",
    "    return f\"Search results for: {query}\\n- France has a population of 67.75 million people (2023 estimate)\\n- Paris is the capital of France\"\n",
    "\n",
    "@tool\n",
    "def calculator(expression: str) -> str:\n",
    "    \"\"\"Evaluate a mathematical expression.\"\"\"\n",
    "    try:\n",
    "        return str(eval(expression))\n",
    "    except Exception as e:\n",
    "        return f\"Error in calculation: {e}\"\n",
    "\n",
    "# Step 2: Initialize the language model\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "# Step 3: Create the ReAct agent prompt\n",
    "react_prompt_template = \"\"\"\n",
    "You are a helpful assistant. Use the following tools to answer the user's question:\n",
    "{tools}\n",
    "\n",
    "Use the following format:\n",
    "Question: the input question\n",
    "Thought: you should always think about what to do\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "Question: {input}\n",
    "{agent_scratchpad}\n",
    "\"\"\"\n",
    "\n",
    "# Create a PromptTemplate object instead of a raw string\n",
    "react_prompt = PromptTemplate.from_template(react_prompt_template)\n",
    "\n",
    "# Step 4: Create the ReAct agent\n",
    "react_agent = create_react_agent(llm, [search, calculator], react_prompt)\n",
    "\n",
    "# Step 5: Create the agent executor\n",
    "react_executor = AgentExecutor(\n",
    "    agent=react_agent,\n",
    "    tools=[search, calculator],\n",
    "    verbose=True,\n",
    "    return_intermediate_steps=True\n",
    ")\n",
    "\n",
    "# Step 6: Run the agent\n",
    "if __name__ == \"__main__\":\n",
    "    response = react_executor.invoke({\"input\": \"What is the population of France multiplied by 2?\"})\n",
    "    print(\"\\nFinal Response:\")\n",
    "    print(response[\"output\"])\n",
    "    \n",
    "    # You can also examine the intermediate steps\n",
    "    print(\"\\nIntermediate Steps:\")\n",
    "    for step in response[\"intermediate_steps\"]:\n",
    "        print(step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. OpenAI Functions Agent**\n",
    "- The OpenAI Functions agent leverages OpenAI's function calling capability, providing more structured tool usage.\n",
    "\n",
    "#### **Key characteristics:**\n",
    "\n",
    "- More efficient with OpenAI models\n",
    "- Cleaner output with less hallucination in tool selection\n",
    "- Better at understanding which tool to use when\n",
    "\n",
    "- This agent is best for : Applications using OpenAI models ,\n",
    "Tasks requiring accurate tool selection ,\n",
    "User-facing applications where clean outputs matter ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `search_weather` with `{'location': 'San Francisco'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mWeather in San Francisco: Partly cloudy, 72°F (22°C)\u001b[0m\u001b[32;1m\u001b[1;3mThe weather in San Francisco is currently partly cloudy with a temperature of 72°F (22°C).\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Weather Query Response:\n",
      "The weather in San Francisco is currently partly cloudy with a temperature of 72°F (22°C).\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `search_restaurants` with `{'cuisine': 'Italian', 'location': 'New York'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mTop Italian restaurants in New York:\n",
      "1. Example Restaurant (4.5 stars)\n",
      "2. Sample Eatery (4.3 stars)\u001b[0m\u001b[32;1m\u001b[1;3mHere are some Italian restaurants in New York that you might enjoy:\n",
      "1. Example Restaurant (4.5 stars)\n",
      "2. Sample Eatery (4.3 stars)\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Restaurant Query Response:\n",
      "Here are some Italian restaurants in New York that you might enjoy:\n",
      "1. Example Restaurant (4.5 stars)\n",
      "2. Sample Eatery (4.3 stars)\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `search_weather` with `{'location': 'Chicago'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mWeather in Chicago: Partly cloudy, 72°F (22°C)\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `search_restaurants` with `{'cuisine': 'Thai', 'location': 'Chicago'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mTop Thai restaurants in Chicago:\n",
      "1. Example Restaurant (4.5 stars)\n",
      "2. Sample Eatery (4.3 stars)\u001b[0m\u001b[32;1m\u001b[1;3mThe weather in Chicago tomorrow will be partly cloudy with a temperature of 72°F (22°C). You may not need a jacket during the day, but it might get cooler in the evening.\n",
      "\n",
      "For Thai food, here are some top Thai restaurants in Chicago:\n",
      "1. Example Restaurant (4.5 stars)\n",
      "2. Sample Eatery (4.3 stars)\n",
      "\n",
      "Enjoy your visit to Chicago and your Thai dining experience!\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Complex Query Response:\n",
      "The weather in Chicago tomorrow will be partly cloudy with a temperature of 72°F (22°C). You may not need a jacket during the day, but it might get cooler in the evening.\n",
      "\n",
      "For Thai food, here are some top Thai restaurants in Chicago:\n",
      "1. Example Restaurant (4.5 stars)\n",
      "2. Sample Eatery (4.3 stars)\n",
      "\n",
      "Enjoy your visit to Chicago and your Thai dining experience!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "OpenAI Functions Agent Example\n",
    "\n",
    "This example demonstrates how to create an OpenAI Functions agent in LangChain.\n",
    "This agent type leverages OpenAI's function calling capability for more structured tool usage.\n",
    "\"\"\"\n",
    "\n",
    "from langchain_core.tools import tool\n",
    "from langchain.agents import AgentExecutor, create_openai_functions_agent\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Step 1: Define tools the agent can use\n",
    "@tool\n",
    "def search_weather(location: str) -> str:\n",
    "    \"\"\"Search for current weather in a specific location.\"\"\"\n",
    "    # In a real implementation, this would connect to a weather API\n",
    "    return f\"Weather in {location}: Partly cloudy, 72°F (22°C)\"\n",
    "\n",
    "@tool\n",
    "def search_restaurants(cuisine: str, location: str) -> str:\n",
    "    \"\"\"Find restaurants of a specific cuisine in a given location.\"\"\"\n",
    "    # In a real implementation, this would connect to a restaurant search API\n",
    "    return f\"Top {cuisine} restaurants in {location}:\\n1. Example Restaurant (4.5 stars)\\n2. Sample Eatery (4.3 stars)\"\n",
    "\n",
    "# Step 2: Initialize the language model (must support function calling)\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "# Step 3: Create a prompt template\n",
    "functions_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful travel assistant. Use the tools provided to answer the user's questions about weather and dining options.\"),\n",
    "    (\"user\", \"{input}\"),\n",
    "    MessagesPlaceholder(variable_name=\"agent_scratchpad\")  # Add this line\n",
    "])\n",
    "\n",
    "# Step 4: Create the OpenAI Functions agent\n",
    "tools = [search_weather, search_restaurants]\n",
    "functions_agent = create_openai_functions_agent(llm, tools, functions_prompt)\n",
    "\n",
    "# Step 5: Create the agent executor\n",
    "functions_executor = AgentExecutor(\n",
    "    agent=functions_agent,\n",
    "    tools=tools,\n",
    "    verbose=True,\n",
    "    return_intermediate_steps=True\n",
    ")\n",
    "\n",
    "# Step 6: Run the agent\n",
    "if __name__ == \"__main__\":\n",
    "    # Example 1: Weather query\n",
    "    weather_response = functions_executor.invoke(\n",
    "        {\"input\": \"What's the weather like in San Francisco?\"}\n",
    "    )\n",
    "    print(\"\\nWeather Query Response:\")\n",
    "    print(weather_response[\"output\"])\n",
    "    \n",
    "    # Example 2: Restaurant query\n",
    "    restaurant_response = functions_executor.invoke(\n",
    "        {\"input\": \"I'm in New York and I want to eat Italian food. Any suggestions?\"}\n",
    "    )\n",
    "    print(\"\\nRestaurant Query Response:\")\n",
    "    print(restaurant_response[\"output\"])\n",
    "    \n",
    "    # Example 3: Multi-step query\n",
    "    complex_response = functions_executor.invoke(\n",
    "        {\"input\": \"I'm visiting Chicago tomorrow. Will I need a jacket? Also, I love Thai food - any good places to eat?\"}\n",
    "    )\n",
    "    print(\"\\nComplex Query Response:\")\n",
    "    print(complex_response[\"output\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Structured Output Agent\n",
    "The Structured Output agent ensures responses conform to specific schemas, making it excellent for applications requiring consistent data formats.\n",
    "\n",
    "\n",
    "#### Key characteristics:\n",
    "\n",
    "- Returns data in predefined Pydantic models\n",
    "- Enforces schema validation\n",
    "- Ideal for integrating with typed systems\n",
    "\n",
    "- This agent shines in : Product recommendations ,\n",
    "Data extraction tasks ,\n",
    "API integration where consistent output structure is critical ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `ArticleOutlineGenerator` with `Artificial Intelligence`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m{'title': 'The Rise of Artificial Intelligence: A Comprehensive Overview', 'summary': 'This article explores the evolution of artificial intelligence, its current applications, and the potential impact on various industries.', 'key_points': \"1. History of AI and its milestones, 2. Common AI applications in everyday life, 3. AI's role in healthcare, finance, and transportation industries\", 'audience': 'Technology enthusiasts, professionals in AI-related fields, and individuals interested in the future of technology'}\u001b[0m\u001b[32;1m\u001b[1;3mThe article outline on \"The Rise of Artificial Intelligence: A Comprehensive Overview\" is structured as follows:\n",
      "\n",
      "- **Title**: The Rise of Artificial Intelligence: A Comprehensive Overview\n",
      "- **Summary**: This article explores the evolution of artificial intelligence, its current applications, and the potential impact on various industries.\n",
      "- **Key Points**:\n",
      "  1. History of AI and its milestones\n",
      "  2. Common AI applications in everyday life\n",
      "  3. AI's role in healthcare, finance, and transportation industries\n",
      "- **Intended Audience**: Technology enthusiasts, professionals in AI-related fields, and individuals interested in the future of technology\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "The article outline on \"The Rise of Artificial Intelligence: A Comprehensive Overview\" is structured as follows:\n",
      "\n",
      "- **Title**: The Rise of Artificial Intelligence: A Comprehensive Overview\n",
      "- **Summary**: This article explores the evolution of artificial intelligence, its current applications, and the potential impact on various industries.\n",
      "- **Key Points**:\n",
      "  1. History of AI and its milestones\n",
      "  2. Common AI applications in everyday life\n",
      "  3. AI's role in healthcare, finance, and transportation industries\n",
      "- **Intended Audience**: Technology enthusiasts, professionals in AI-related fields, and individuals interested in the future of technology\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from langchain.output_parsers.structured import StructuredOutputParser, ResponseSchema\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
    "from langchain_core.tools import Tool\n",
    "\n",
    "# Define the response schemas\n",
    "response_schemas = [\n",
    "    ResponseSchema(name=\"title\", description=\"The title of the article\"),\n",
    "    ResponseSchema(name=\"summary\", description=\"A brief summary of the article's content\"),\n",
    "    ResponseSchema(name=\"key_points\", description=\"3-5 key points from the article\"),\n",
    "    ResponseSchema(name=\"audience\", description=\"The intended audience for this article\")\n",
    "]\n",
    "\n",
    "# Create the parser\n",
    "parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "format_instructions = parser.get_format_instructions()\n",
    "\n",
    "# Create a tool that generates article outlines\n",
    "def generate_article_outline(topic):\n",
    "    \"\"\"Generate an article outline for a given topic.\"\"\"\n",
    "    prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "    Write an article outline about {topic}.\n",
    "    {format_instructions}\n",
    "    \"\"\")\n",
    "    \n",
    "    formatted_prompt = prompt.format(\n",
    "        format_instructions=format_instructions,\n",
    "        topic=topic\n",
    "    )\n",
    "    \n",
    "    model = ChatOpenAI(temperature=0)\n",
    "    response = model.invoke(formatted_prompt)\n",
    "    \n",
    "    # Parse the response\n",
    "    return parser.parse(response.content)\n",
    "\n",
    "# Create a tool for the agent to use\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"ArticleOutlineGenerator\",\n",
    "        description=\"Generates a structured outline for an article on a given topic\",\n",
    "        func=generate_article_outline\n",
    "    )\n",
    "]\n",
    "\n",
    "# Create a prompt for the agent - FIX: Adding agent_scratchpad\n",
    "agent_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"You are an assistant that helps create article outlines.\n",
    "    Use the provided tools to generate comprehensive article outlines when given a topic.\n",
    "    Always use the ArticleOutlineGenerator tool to create the outline.\"\"\"),\n",
    "    (\"human\", \"{input}\"),\n",
    "    # Add the MessagesPlaceholder for agent_scratchpad\n",
    "    MessagesPlaceholder(variable_name=\"agent_scratchpad\")\n",
    "])\n",
    "\n",
    "# Create the model for the agent\n",
    "model = ChatOpenAI(temperature=0)\n",
    "\n",
    "# Create the agent\n",
    "agent = create_openai_tools_agent(model, tools, agent_prompt)\n",
    "\n",
    "# Create the agent executor\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools , verbose=True)\n",
    "\n",
    "# Example usage\n",
    "result = agent_executor.invoke({\"input\": \"Create an article outline about artificial intelligence\"})\n",
    "print(result[\"output\"])\n",
    "\n",
    "# To access the structured data:\n",
    "# After getting the result, you could extract the structured data from the response\n",
    "# You might need to parse it from the output text if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent Executors\n",
    "\n",
    "Agent executors are responsible for managing the execution of agents. They handle the flow of data and ensure that agents operate efficiently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agent Executors help run Agents + Tools together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `Calculator` with `{'expression': '4-5*6'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m-26\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `JokeTool` with `{}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mWhy don't scientists trust atoms? Because they make up everything!\u001b[0m\u001b[32;1m\u001b[1;3mThe result of the expression 4-5*6 is -26.\n",
      "\n",
      "Here's a joke for you: Why don't scientists trust atoms? Because they make up everything!\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "The result of the expression 4-5*6 is -26.\n",
      "\n",
      "Here's a joke for you: Why don't scientists trust atoms? Because they make up everything!\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.tools import StructuredTool\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from typing import Union \n",
    "\n",
    "# Define a custom tool for telling jokes\n",
    "def tell_joke() -> str:\n",
    "    \"\"\"Tells a random joke.\"\"\"\n",
    "    return \"Why don't scientists trust atoms? Because they make up everything!\"\n",
    "\n",
    "# Create a StructuredTool instance\n",
    "joke_tool = StructuredTool.from_function(\n",
    "    func=tell_joke,\n",
    "    name=\"JokeTool\",\n",
    "    description=\"Tells a random joke.\"\n",
    ")\n",
    "\n",
    "# Define a custom tool for mathematical calculations\n",
    "def math_tool(expression: str) -> Union[float, str]:\n",
    "    \"\"\"Evaluates a mathematical expression.\"\"\"\n",
    "    try:\n",
    "        return eval(expression)\n",
    "    except Exception as e:\n",
    "        return f\"Error in calculation: {str(e)}\"\n",
    "\n",
    "# Create a StructuredTool instance\n",
    "calculator_tool = StructuredTool.from_function(\n",
    "    func=math_tool,\n",
    "    name=\"Calculator\",\n",
    "    description=\"Evaluates a mathematical expression.\"\n",
    ")\n",
    "\n",
    "# Initialize the LLM\n",
    "llm = ChatOpenAI(model_name=\"gpt-4\", temperature=0)\n",
    "\n",
    "# Define the prompt template\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant with access to tools.\"),\n",
    "    MessagesPlaceholder(variable_name=\"agent_scratchpad\"),  # Placeholder for intermediate steps\n",
    "    (\"user\", \"{input}\"),  # User input\n",
    "    MessagesPlaceholder(variable_name=\"agent_scratchpad\")  # Placeholder for intermediate steps\n",
    "])\n",
    "\n",
    "# Create the OpenAI tools agent\n",
    "tools = [joke_tool , calculator_tool]\n",
    "agent = create_openai_tools_agent(llm=llm, tools=tools, prompt=prompt)\n",
    "\n",
    "# Wrap the agent in an executor\n",
    "executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "# Run the agent using invoke\n",
    "# response = executor.invoke({\"input\": \"Tell me a joke.\"})\n",
    "# print(response[\"output\"])  # Access the output explicitly\n",
    "\n",
    "response = executor.invoke({\"input\": \"what is 4-5*6 and tell me some joke.\"})\n",
    "print(response[\"output\"])  # Access the output explicitly\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Simple Agent\n",
    "\n",
    "Let's build a simple agent to understand the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `Calculator` with `{'expression': '12 + 45'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m57\u001b[0m\u001b[32;1m\u001b[1;3mThe result of 12 + 45 is 57.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "The result of 12 + 45 is 57.\n"
     ]
    }
   ],
   "source": [
    "# Updated Simple Math Agent\n",
    "from langchain_community.callbacks import get_openai_callback  # Optional: Track token usage\n",
    "from langchain_openai import ChatOpenAI  # Replaces OpenAI from langchain.llms\n",
    "from langchain.agents import create_openai_tools_agent, AgentExecutor  # Modern agent creation\n",
    "from langchain.tools import StructuredTool  # Replaces Tool for better structure\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder  # For defining prompts\n",
    "from typing import Union  # Import Union for type hints\n",
    "\n",
    "# Define a custom tool for mathematical calculations\n",
    "def math_tool(expression: str) -> Union[float, str]:\n",
    "    \"\"\"Evaluates a mathematical expression.\"\"\"\n",
    "    try:\n",
    "        return eval(expression)\n",
    "    except Exception as e:\n",
    "        return f\"Error in calculation: {str(e)}\"\n",
    "\n",
    "# Create a StructuredTool instance\n",
    "calculator_tool = StructuredTool.from_function(\n",
    "    func=math_tool,\n",
    "    name=\"Calculator\",\n",
    "    description=\"Evaluates a mathematical expression.\"\n",
    ")\n",
    "\n",
    "# Initialize the LLM\n",
    "llm = ChatOpenAI(model_name=\"gpt-4\", temperature=0)\n",
    "\n",
    "# Define the prompt template\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant with access to tools.\"),\n",
    "    MessagesPlaceholder(variable_name=\"agent_scratchpad\"),  # Placeholder for intermediate steps\n",
    "    (\"user\", \"{input}\"),  # User input\n",
    "    MessagesPlaceholder(variable_name=\"agent_scratchpad\")  # Placeholder for intermediate steps\n",
    "])\n",
    "\n",
    "# Create the OpenAI tools agent\n",
    "tools = [calculator_tool]\n",
    "agent = create_openai_tools_agent(llm=llm, tools=tools, prompt=prompt)\n",
    "\n",
    "# Wrap the agent in an executor\n",
    "executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "# Run the agent using invoke\n",
    "response = executor.invoke({\"input\": \"What is 12 + 45?\"})\n",
    "print(response[\"output\"])  # Access the output explicitly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Prebuilt Agents vs. Custom Agents\n",
    "\n",
    "LangChain offers both prebuilt agents and the flexibility to create custom agents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prebuilt Agents\n",
    "\n",
    "- **Advantages**: Quick setup, proven reliability\n",
    "- **Use Cases**: Standard tasks, rapid prototyping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Agents\n",
    "\n",
    "- **Advantages**: Tailored to specific needs, flexible\n",
    "- **Use Cases**: Unique workflows, specialized applications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Agents are a powerful feature of LangChain, enabling complex and autonomous operations. Understanding the different types of agents and how to use them effectively is crucial for building advanced AI applications.\n",
    "\n",
    "In the next notebook, we'll explore real-world applications of agents and how they can be integrated into larger systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

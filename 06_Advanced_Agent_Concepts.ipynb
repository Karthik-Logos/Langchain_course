{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set the API key in the environment variable\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = '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'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Advanced Agent Concepts\n",
    "\n",
    "In this notebook, we will explore advanced concepts in agent design and implementation using LangChain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Multi-Agent Systems (Collaborative & Competitive Agents)\n",
    "\n",
    "Multi-agent systems involve multiple agents working together or competing to complete tasks.\n",
    "\n",
    "- Collaborative Agents – Work together, each specializing in a specific task.\n",
    "- Competitive Agents – Compete to find the best solution (e.g., auction-based bidding)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. Collaborative Agents\n",
    "\n",
    "- Work together to achieve shared objectives\n",
    "- Example: Agents collaborating to solve a complex problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to solve a multiplication problem and also find out the weather in Paris.\n",
      "Action: Calculator\n",
      "Action Input: 12 * 8\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m96\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI have solved the math problem. Now I need to find out the weather in Paris.\n",
      "Action: WeatherAPI\n",
      "Action Input: Paris\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mThe weather in Paris is 22°C, sunny.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer.\n",
      "Final Answer: 12 * 8 equals 96 and the weather in Paris is 22°C, sunny.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "12 * 8 equals 96 and the weather in Paris is 22°C, sunny.\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import initialize_agent, AgentType\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.tools import Tool\n",
    "\n",
    "# Define two specialized tools\n",
    "def calculator(expression):\n",
    "    return eval(expression)\n",
    "\n",
    "def get_weather(city):\n",
    "    return f\"The weather in {city} is 22°C, sunny.\"\n",
    "\n",
    "math_tool = Tool(name=\"Calculator\", func=calculator, description=\"Solves math problems.\")\n",
    "weather_tool = Tool(name=\"WeatherAPI\", func=get_weather, description=\"Provides weather updates.\")\n",
    "\n",
    "# Initialize two agents\n",
    "llm = ChatOpenAI(model_name=\"gpt-4\")\n",
    "collaborative_agent = initialize_agent(\n",
    "    tools=[math_tool, weather_tool], llm=llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True\n",
    ")\n",
    "\n",
    "response = collaborative_agent.run(\"What is 12 * 8? Also, what's the weather in Paris?\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Competitive Agents\n",
    "\n",
    "- Compete to achieve individual goals\n",
    "- Example: Agents competing in a game scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `Calculator` with `24*7`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m168\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `Calculator` with `24*7+15`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m183\u001b[0m\u001b[32;1m\u001b[1;3mThe result of 24 × 7 is 168, and the result of 24 × 7 + 15 is 183.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `Calculator` with `24*7`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m168\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `Calculator` with `24*7+15`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m183\u001b[0m\u001b[32;1m\u001b[1;3mThe result of \\(24 \\times 7\\) is 168.  \n",
      "Adding 15 to this result gives us 183.  \n",
      "Therefore, the final result of \\(24 \\times 7 + 15\\) is 183.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'What is the result of 24 × 7 + 15?',\n",
       " 'concise': 'The result of 24 × 7 is 168, and the result of 24 × 7 + 15 is 183.',\n",
       " 'detailed': 'The result of \\\\(24 \\\\times 7\\\\) is 168.  \\nAdding 15 to this result gives us 183.  \\nTherefore, the final result of \\\\(24 \\\\times 7 + 15\\\\) is 183.',\n",
       " 'judgment': 'I would choose \"CONCISE\" as the winner in this case. While both responses provide accurate information, the concise response is more efficient and straightforward in delivering the answer. It clearly states the final result without unnecessary details. I would rate \"CONCISE\" a 9/10 and \"DETAILED\" a 7/10.'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import create_openai_tools_agent, AgentExecutor\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.tools import Tool\n",
    "\n",
    "\n",
    "\n",
    "# Create a calculator tool\n",
    "def calculator(expression):\n",
    "    \"\"\"Evaluate a mathematical expression.\"\"\"\n",
    "    try:\n",
    "        return str(eval(expression))\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "calculator_tool = Tool(\n",
    "    name=\"Calculator\",\n",
    "    func=calculator,\n",
    "    description=\"Useful for performing mathematical calculations.\"\n",
    ")\n",
    "\n",
    "# Create prompt templates for different agent styles\n",
    "concise_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a concise assistant. Provide brief, to-the-point answers.\"),\n",
    "    (\"human\", \"{input}\"),\n",
    "    MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "])\n",
    "\n",
    "detailed_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a detailed assistant. Provide comprehensive answers with examples.\"),\n",
    "    (\"human\", \"{input}\"),\n",
    "    MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "])\n",
    "\n",
    "# Create LLMs and agents\n",
    "llm = ChatOpenAI(temperature=0.1)\n",
    "concise_agent = create_openai_tools_agent(llm, [calculator_tool], concise_prompt)\n",
    "detailed_agent = create_openai_tools_agent(llm, [calculator_tool], detailed_prompt)\n",
    "\n",
    "# Create agent executors\n",
    "concise_executor = AgentExecutor(agent=concise_agent, tools=[calculator_tool], verbose=True)\n",
    "detailed_executor = AgentExecutor(agent=detailed_agent, tools=[calculator_tool], verbose=True)\n",
    "\n",
    "# Run a simple competition\n",
    "question = \"What is the result of 24 × 7 + 15?\"\n",
    "concise_result = concise_executor.invoke({\"input\": question})\n",
    "detailed_result = detailed_executor.invoke({\"input\": question})\n",
    "\n",
    "# Judge the responses\n",
    "judge_llm = ChatOpenAI(temperature=0.1)\n",
    "judge_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "You are evaluating two AI assistants' responses.\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Concise: {concise_response}\n",
    "Detailed: {detailed_response}\n",
    "\n",
    "Choose \"CONCISE\" or \"DETAILED\" as winner based on accuracy, helpfulness, and efficiency.\n",
    "Explain in 2-3 sentences and rate both on scale 1-10.\n",
    "\"\"\")\n",
    "\n",
    "judgment = judge_llm.invoke(judge_prompt.format(\n",
    "    question=question,\n",
    "    concise_response=concise_result[\"output\"],\n",
    "    detailed_response=detailed_result[\"output\"]\n",
    "))\n",
    "\n",
    "# Example usage:\n",
    "# Run this with your own questions to see which style works better\n",
    "results = {\"question\": question, \"concise\": concise_result[\"output\"], \n",
    "           \"detailed\": detailed_result[\"output\"], \"judgment\": judgment.content}\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent Routing (Router Chains & Dynamic Decision Making)\n",
    "\n",
    "Router Chains decide which specialized agent should handle a request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThis question should be routed to the math agent.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Routing Response: This question should be routed to the math agent.\n",
      "Routing to Math Agent...\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `Calculator` with `12 * 8`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m96\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `Calculator` with `12 * 8`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m96\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `Calculator` with `12 * 8`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m96\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `Calculator` with `12 * 8`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m96\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `Calculator` with `12 * 8`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m96\u001b[0m\u001b[32;1m\u001b[1;3mThe result of 12 * 8 is 96.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Final Answer: The result of 12 * 8 is 96.\n"
     ]
    }
   ],
   "source": [
    "# Standard Library Imports\n",
    "import os\n",
    "\n",
    "# LangChain Core Imports\n",
    "from langchain_openai import ChatOpenAI  # For interacting with OpenAI models\n",
    "from langchain.agents import create_openai_tools_agent, AgentExecutor  # For creating and executing agents\n",
    "from langchain.tools import Tool  # For defining custom tools\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder  # For defining prompt templates\n",
    "from langchain_core.utils.function_calling import convert_to_openai_tool  # For converting tools to OpenAI format\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "# Set the OpenAI API key (replace \"your-api-key-here\" with your actual key)\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "\n",
    "# Define specialized tools\n",
    "def calculator(expression):\n",
    "    return eval(expression)\n",
    "\n",
    "def get_weather(city):\n",
    "    return f\"The weather in {city} is 22°C, sunny.\"\n",
    "\n",
    "math_tool = Tool(name=\"Calculator\", func=calculator, description=\"Solves math problems.\")\n",
    "weather_tool = Tool(name=\"WeatherAPI\", func=get_weather, description=\"Provides weather updates.\")\n",
    "\n",
    "# Initialize LLMs for agents\n",
    "llm_router = ChatOpenAI(model_name=\"gpt-4\", temperature=0.0)  # Router agent (factual and precise)\n",
    "llm_math = ChatOpenAI(model_name=\"gpt-4\", temperature=0.0)  # Math agent\n",
    "llm_weather = ChatOpenAI(model_name=\"gpt-4\", temperature=0.0)  # Weather agent\n",
    "\n",
    "# Define the tools for each agent\n",
    "tools_math = [math_tool]\n",
    "tools_weather = [weather_tool]\n",
    "\n",
    "# Define the prompt template for the router agent\n",
    "router_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a router agent. Route the user's question to the appropriate agent.\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),  # Add agent_scratchpad placeholder\n",
    "        (\"user\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Define the prompt templates for the specialized agents\n",
    "math_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a math expert. Solve the given math problem.\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "        (\"user\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "weather_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a weather expert. Provide the requested weather information.\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "        (\"user\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create the agents\n",
    "router_agent = create_openai_tools_agent(llm_router, [], router_prompt)\n",
    "math_agent = create_openai_tools_agent(llm_math, tools_math, math_prompt)\n",
    "weather_agent = create_openai_tools_agent(llm_weather, tools_weather, weather_prompt)\n",
    "\n",
    "# Wrap the agents in executors\n",
    "router_executor = AgentExecutor(agent=router_agent, tools=[], verbose=True)\n",
    "math_executor = AgentExecutor(agent=math_agent, tools=tools_math, verbose=True)\n",
    "weather_executor = AgentExecutor(agent=weather_agent, tools=tools_weather, verbose=True)\n",
    "\n",
    "# Function to route the input to the appropriate agent\n",
    "def route_and_execute(input_question):\n",
    "    # Step 1: Router agent determines which agent to use\n",
    "    routing_response = router_executor.invoke({\"input\": input_question})\n",
    "    print(\"Routing Response:\", routing_response[\"output\"])\n",
    "    \n",
    "    # Step 2: Extract the decision from the router agent's response\n",
    "    if \"math\" in routing_response[\"output\"].lower():\n",
    "        print(\"Routing to Math Agent...\")\n",
    "        result = math_executor.invoke({\"input\": input_question})\n",
    "    elif \"weather\" in routing_response[\"output\"].lower():\n",
    "        print(\"Routing to Weather Agent...\")\n",
    "        result = weather_executor.invoke({\"input\": input_question})\n",
    "    else:\n",
    "        result = {\"output\": \"No suitable agent found.\"}\n",
    "    \n",
    "    return result[\"output\"]\n",
    "\n",
    "# # Test the agent routing system\n",
    "question = \"What is 12 * 8?\"\n",
    "print(\"Final Answer:\", route_and_execute(question))\n",
    "\n",
    "# question = \"What's the weather like in Paris?\"\n",
    "# print(\"Final Answer:\", route_and_execute(question))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent Memory & Persistent Storage\n",
    "\n",
    "Agent memory allows agents to store and retrieve information across interactions, enabling more coherent and context-aware behavior.\n",
    "\n",
    "Agents can remember previous interactions using memory or databases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a) Using Conversation Memory\n",
    "Stores past messages for context-aware responses.\n",
    "This is an in-memory solution for maintaining conversational context:\n",
    "\n",
    "- **Temporary:** Exists only during the runtime of the application\n",
    "- **Scope:** Limited to the current conversation session\n",
    "- **Usage:** Stores chat history, previous interactions, and short-term context\n",
    "- **Implementation:** Simple to use, requires minimal setup\n",
    "- **Best for:** Maintaining conversation flow and context within a single session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? No\n",
      "AI: Nice to meet you, John! How can I assist you today?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Nice to meet you, John! How can I assist you today?\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? No\n",
      "AI: Your name is John.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Your name is John.\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.agents import initialize_agent, AgentType\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4\")\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
    "\n",
    "agent_with_memory = initialize_agent(\n",
    "    llm=llm, agent=AgentType.CONVERSATIONAL_REACT_DESCRIPTION, tools=[], memory=memory, verbose=True\n",
    ")\n",
    "\n",
    "print(agent_with_memory.run(\"My name is John.\"))\n",
    "print(agent_with_memory.run(\"What is my name?\"))  # Remembers \"John\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Persistent Storage\n",
    "\n",
    "- Store data for long-term use . \n",
    "This involves storing data in external databases or file systems:\n",
    "\n",
    "- **Permanent:** Data survives application restarts\n",
    "- **Scope:** Can span multiple sessions and users\n",
    "- **Usage:** Stores long-term knowledge, user preferences, and system state\n",
    "- **Implementation:** Requires integration with external storage systems\n",
    "- **Best for:** Long-running applications, remembering user preferences across sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `Calculator` with `12 * 8`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m96\u001b[0m\u001b[32;1m\u001b[1;3mThe result of 12 * 8 is 96.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Agent Response: The result of 12 * 8 is 96.\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThe result of the previous calculation was 96.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Agent Response: The result of the previous calculation was 96.\n"
     ]
    }
   ],
   "source": [
    "# Standard Library Imports\n",
    "import os\n",
    "import sqlite3\n",
    "import json\n",
    "\n",
    "# LangChain Core Imports\n",
    "from langchain_openai import ChatOpenAI  # For interacting with OpenAI models\n",
    "from langchain.agents import create_openai_tools_agent, AgentExecutor  # For creating and executing agents\n",
    "from langchain.tools import Tool  # For defining custom tools\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder  # For defining prompt templates\n",
    "from langchain_core.utils.function_calling import convert_to_openai_tool  # For converting tools to OpenAI format\n",
    "\n",
    "# Optional Typing Imports\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "# Set the OpenAI API key (replace \"your-api-key-here\" with your actual key)\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "\n",
    "# Define specialized tools\n",
    "def calculator(expression):\n",
    "    return eval(expression)\n",
    "\n",
    "def get_weather(city):\n",
    "    return f\"The weather in {city} is 22°C, sunny.\"\n",
    "\n",
    "math_tool = Tool(name=\"Calculator\", func=calculator, description=\"Solves math problems.\")\n",
    "weather_tool = Tool(name=\"WeatherAPI\", func=get_weather, description=\"Provides weather updates.\")\n",
    "\n",
    "# Initialize LLM\n",
    "llm = ChatOpenAI(model_name=\"gpt-4\", temperature=0.0)\n",
    "\n",
    "# Define the tools for the agent\n",
    "tools = [math_tool, weather_tool]\n",
    "\n",
    "# Define the prompt template for the agent\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant.\"),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),  # Placeholder for chat history\n",
    "        (\"user\", \"{input}\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),  # Placeholder for intermediate steps\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Convert tools to OpenAI format\n",
    "openai_tools = [convert_to_openai_tool(tool) for tool in tools]\n",
    "\n",
    "# Create the agent\n",
    "agent = create_openai_tools_agent(llm, tools, prompt)\n",
    "\n",
    "# Wrap the agent in an executor\n",
    "executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "# SQLite Database Integration\n",
    "class AgentMemory:\n",
    "    def __init__(self, db_path=\"agent_memory_latest.db\"):\n",
    "        self.conn = sqlite3.connect(db_path)\n",
    "        self.cursor = self.conn.cursor()\n",
    "        self._initialize_db()\n",
    "\n",
    "    def _initialize_db(self):\n",
    "        \"\"\"Create the table if it doesn't exist.\"\"\"\n",
    "        self.cursor.execute(\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS memory (\n",
    "                session_id TEXT PRIMARY KEY,\n",
    "                chat_history TEXT\n",
    "            )\n",
    "        \"\"\")\n",
    "        self.conn.commit()\n",
    "\n",
    "    def store_chat_history(self, session_id: str, chat_history: List[Dict[str, str]]):\n",
    "        \"\"\"Store the chat history for a given session ID.\"\"\"\n",
    "        serialized_chat_history = json.dumps(chat_history)\n",
    "        self.cursor.execute(\"INSERT OR REPLACE INTO memory VALUES (?, ?)\", (session_id, serialized_chat_history))\n",
    "        self.conn.commit()\n",
    "\n",
    "    def retrieve_chat_history(self, session_id: str) -> List[Dict[str, str]]:\n",
    "        \"\"\"Retrieve the chat history for a given session ID.\"\"\"\n",
    "        self.cursor.execute(\"SELECT chat_history FROM memory WHERE session_id=?\", (session_id,))\n",
    "        result = self.cursor.fetchone()\n",
    "        return json.loads(result[0]) if result else []\n",
    "\n",
    "    def close(self):\n",
    "        \"\"\"Close the database connection.\"\"\"\n",
    "        self.conn.close()\n",
    "\n",
    "# Initialize AgentMemory\n",
    "agent_memory = AgentMemory()\n",
    "\n",
    "# Function to interact with the agent using persistent storage\n",
    "def interact_with_agent(question: str, session_id: str):\n",
    "    # Retrieve the chat history for the session\n",
    "    chat_history = agent_memory.retrieve_chat_history(session_id)\n",
    "\n",
    "    # Invoke the agent with the current question and chat history\n",
    "    response = executor.invoke({\n",
    "        \"input\": question,\n",
    "        \"chat_history\": chat_history,  # Pass the retrieved chat history\n",
    "    })\n",
    "\n",
    "    # Extract the agent's response\n",
    "    agent_response = response[\"output\"]\n",
    "\n",
    "    # Update the chat history\n",
    "    chat_history.append({\"role\": \"user\", \"content\": question})\n",
    "    chat_history.append({\"role\": \"assistant\", \"content\": agent_response})\n",
    "\n",
    "    # Store the updated chat history in the database\n",
    "    agent_memory.store_chat_history(session_id, chat_history)\n",
    "\n",
    "    return agent_response\n",
    "\n",
    "# Test the agent with memory integration\n",
    "session_id = \"user_session_1\"\n",
    "\n",
    "question1 = \"What is 12 * 8?\"\n",
    "print(\"Agent Response:\", interact_with_agent(question1, session_id))\n",
    "\n",
    "question2 = \"What was the result of the previous calculation?\"\n",
    "print(\"Agent Response:\", interact_with_agent(question2, session_id))\n",
    "\n",
    "# Close the database connection\n",
    "# agent_memory.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mYour name is Karthik K C.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Agent Response: Your name is Karthik K C.\n"
     ]
    }
   ],
   "source": [
    "question2 = \"what is my name \"\n",
    "print(\"Agent Response:\", interact_with_agent(question2, session_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **When to use which?**\n",
    "\n",
    "- Use **ConversationBufferMemory**  for simple applications where you only need to maintain context within a single conversation\n",
    "\n",
    "#### - Use **Persistent Storage** when:\n",
    "\n",
    "- You need to remember user data across multiple sessions\n",
    "- You're building a multi-user application\n",
    "- You want to preserve agent knowledge after application restarts\n",
    "- You're implementing features like user preferences or personalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Advanced agent concepts in LangChain enable the creation of sophisticated and adaptive AI systems. Understanding these concepts is crucial for building agents that can operate effectively in dynamic and complex environments.\n",
    "\n",
    "In the next notebook, we'll explore how to apply these concepts in real-world applications."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
